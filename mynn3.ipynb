{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "import sys\n",
    "\n",
    "#load mnist datasets\n",
    "mnist = datasets.fetch_mldata(\"MNIST original\", data_home=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input data & label preprocessing\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(mnist.data, mnist.target, test_size = 1/7)\n",
    "\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test/ 255.\n",
    "\n",
    "#add bias\n",
    "b_train = np.ones((len(X_train), 1))\n",
    "b_test = np.ones((len(X_test), 1))\n",
    "X_train = np.append(X_train, b_train, axis = 1)\n",
    "X_test = np.append(X_test, b_test, axis = 1)\n",
    "\n",
    "#convert to one-hot label\n",
    "Y_train = [[0 if i != y_train[j] else 1 for i in range(10)] for j in range(len(y_train))]\n",
    "Y_test = [[0 if i != y_test[j] else 1 for i in range(10)] for j in range(len(y_test))]\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight init (-1 ~ 1)\n",
    "weight = (1.0 - (-1.0)) * np.random.rand(3, 28*28+1, 28*28+1) -1\n",
    "\n",
    "#define learning rate\n",
    "lr = 0.001\n",
    "\n",
    "#define mu for momentum\n",
    "mu = 0.8\n",
    "\n",
    "#define alpha, g for RMSProp\n",
    "alpha = 0.9\n",
    "g = np.zeros((3, 28*28+1, 28*28+1))\n",
    "\n",
    "#define epoch\n",
    "epoch = 20\n",
    "\n",
    "#define batch size\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fully connected layer\n",
    "def myFCLayer(output_unit, input_data, layer_no):\n",
    "    w = weight[layer_no, 0:output_unit, 0:len(input_data)]\n",
    "    z = np.dot(w, input_data)\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation\n",
    "def myActivation(z, activation):\n",
    "    if activation == \"ReLU\":\n",
    "        y = myReLU(z)\n",
    "        \n",
    "    elif activation == \"softmax\":\n",
    "        y = mySoftmax(len(z), z)\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation function - ReLU\n",
    "def myReLU(z):\n",
    "    y = np.where(z > 0, z, 0)\n",
    "    \n",
    "    return y\n",
    "\n",
    "#activation function - softmax function\n",
    "def mySoftmax(unit_no, input_data):\n",
    "    m = np.max(input_data)\n",
    "    ei = np.exp(input_data - m)\n",
    "    s = np.sum(ei)\n",
    "    y = ei / s\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop out layer\n",
    "def myDropOut(input_data, late):\n",
    "    index = np.random.randint(0, int(len(input_data) * late))\n",
    "    domask = np.ones(len(input_data))\n",
    "    domask[index] = 0\n",
    "    \n",
    "    return domask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate accuracy\n",
    "def myCalcAcc(est, label_data):\n",
    "    est = np.array(est)\n",
    "    label_data = np.array(label_data)\n",
    "    \n",
    "    a = np.argmax(est, axis=1) - np.argmax(label_data, axis=1)\n",
    "    acc = np.sum(a == 0)\n",
    "    acc = acc / label_data.shape[0]\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function - Cross Entropy\n",
    "def myCrossEntropy(est, t):\n",
    "    E = 0\n",
    "    for i in range(len(t)):\n",
    "        Ei = 0\n",
    "        for j in range(len(t[0])):\n",
    "            Ei -= t[i][j] * np.log(est[i][j] + 1e-8)\n",
    "        E += Ei\n",
    "    \n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate Î´ for CrossEntropy + SoftMax\n",
    "def myCalcDeltaOut(est, label_data):\n",
    "    d = est - label_data\n",
    "    \n",
    "    return d\n",
    "\n",
    "def myCalcDelta(delta, step, z):\n",
    "    z = np.array(z)\n",
    "    \n",
    "    wd = np.dot(delta, weight[-step, 0:len(delta[0]), 0:len(z[0])])\n",
    "    fz = np.where(z > 0, 1, 0)\n",
    "    d = wd * fz\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myCalcDE(delta, x):\n",
    "    DE = np.empty((0, len(x[0])))\n",
    "    for i in range(len(delta[0])):\n",
    "        nw = np.array([np.dot(delta[:,i], x)])\n",
    "        DE = np.append(DE, nw, axis=0)\n",
    "\n",
    "    return DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSprop\n",
    "def myWeightUpdate_RMSProp(DE, layer_no):\n",
    "    for i in range(len(DE)):\n",
    "        g_t = g[layer_no - 1, 0:len(DE), 0:len(DE[0])]\n",
    "        w = weight[layer_no - 1, 0:len(DE), 0:len(DE[0])]\n",
    "        \n",
    "        g_t[i] = (alpha * g_t[i]) + (1 - alpha) * (DE[i] ** 2)\n",
    "        w[i] -= (lr / (np.sqrt(g_t[i]) + 1e-8)) * DE[i]\n",
    "        \n",
    "        g[layer_no -1, 0:len(DE), 0:len(DE[0])] = g_t\n",
    "        weight[layer_no - 1, 0:len(DE), 0:len(DE[0])] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Mini Batch\n",
    "def myGetBatch(X, Y, size):\n",
    "    Y = np.array(Y)\n",
    "    rnd_index = np.arange(X.shape[0])\n",
    "    np.random.shuffle(rnd_index)\n",
    "    X_shuf = X[rnd_index, :]\n",
    "    Y_shuf = Y[rnd_index, :]\n",
    "    \n",
    "    for i in range(0, X.shape[0], size):\n",
    "        X_batch = X_shuf[i : i + size]\n",
    "        Y_batch = Y_shuf[i : i + size]\n",
    "        \n",
    "        yield X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1/20] 60000/60000  train_acc = 0.81865000  train_loss = 3.19721179  test_acc = 0.90820000  test_loss = 1.59001585\n",
      "epoch[2/20] 60000/60000  train_acc = 0.92855000  train_loss = 1.21803759  test_acc = 0.93050000  test_loss = 1.18937287\n",
      "epoch[3/20] 60000/60000  train_acc = 0.95051667  train_loss = 0.82853641  test_acc = 0.93560000  test_loss = 1.09466918\n",
      "epoch[4/20] 60000/60000  train_acc = 0.96265000  train_loss = 0.61933668  test_acc = 0.94750000  test_loss = 0.87917559\n",
      "epoch[5/20] 60000/60000  train_acc = 0.97106667  train_loss = 0.47600304  test_acc = 0.95280000  test_loss = 0.80814305\n",
      "epoch[6/20] 60000/60000  train_acc = 0.97725000  train_loss = 0.36469582  test_acc = 0.94970000  test_loss = 0.85223985\n",
      "epoch[7/20] 60000/60000  train_acc = 0.98171667  train_loss = 0.28794266  test_acc = 0.95720000  test_loss = 0.73188930\n",
      "epoch[8/20] 60000/60000  train_acc = 0.98481667  train_loss = 0.23849126  test_acc = 0.95620000  test_loss = 0.75737724\n",
      "epoch[9/20] 60000/60000  train_acc = 0.98788333  train_loss = 0.18713429  test_acc = 0.95600000  test_loss = 0.74190653\n",
      "epoch[10/20] 60000/60000  train_acc = 0.98926667  train_loss = 0.16743525  test_acc = 0.95900000  test_loss = 0.69313252\n",
      "epoch[11/20] 60000/60000  train_acc = 0.99125000  train_loss = 0.13448879  test_acc = 0.95480000  test_loss = 0.76918810\n",
      "epoch[12/20] 60000/60000  train_acc = 0.99166667  train_loss = 0.13006686  test_acc = 0.96090000  test_loss = 0.66626483\n",
      "epoch[13/20] 60000/60000  train_acc = 0.99270000  train_loss = 0.11123658  test_acc = 0.96490000  test_loss = 0.60261345\n",
      "epoch[14/20] 60000/60000  train_acc = 0.99341667  train_loss = 0.10029827  test_acc = 0.96170000  test_loss = 0.65191304\n",
      "epoch[15/20] 60000/60000  train_acc = 0.99396667  train_loss = 0.09152886  test_acc = 0.96030000  test_loss = 0.69008659\n",
      "epoch[16/20] 60000/60000  train_acc = 0.99418333  train_loss = 0.08653572  test_acc = 0.96050000  test_loss = 0.66902716\n",
      "epoch[17/20] 60000/60000  train_acc = 0.99485000  train_loss = 0.07696724  test_acc = 0.96060000  test_loss = 0.68824027\n",
      "epoch[18/20] 60000/60000  train_acc = 0.99465000  train_loss = 0.08008578  test_acc = 0.96430000  test_loss = 0.61546737\n",
      "epoch[19/20] 60000/60000  train_acc = 0.99555000  train_loss = 0.06790685  test_acc = 0.96290000  test_loss = 0.64109605\n",
      "epoch[20/20] 60000/60000  train_acc = 0.99585000  train_loss = 0.05648739  test_acc = 0.96680000  test_loss = 0.57407083\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "t_loss = []\n",
    "test_acc_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "for ep in range(epoch):\n",
    "    train_acc = 0\n",
    "    train_E = 0\n",
    "    cnt = 0\n",
    "  \n",
    "    #training\n",
    "    for X_batch, Y_batch in myGetBatch(X_train, Y_train, batch_size):\n",
    "        est = []\n",
    "        z1list = []\n",
    "        x2list = []\n",
    "        z2list = []\n",
    "        x3list = []\n",
    "        z3list = []\n",
    "        domask1 = []\n",
    "        domask2 = []\n",
    "        \n",
    "        for x1 in X_batch:\n",
    "            #FC1\n",
    "            z1 = myFCLayer(512, x1, 0)\n",
    "            z1 = np.append(z1, 1)           #add bias\n",
    "            z1list.append(z1)\n",
    "            x2 = myActivation(z1, \"ReLU\")\n",
    "            \n",
    "            #DO1\n",
    "            dm1 = myDropOut(x2, 0.2)\n",
    "            domask1.append(dm1)\n",
    "            x2 *= dm1\n",
    "            x2list.append(x2)\n",
    "            \n",
    "            #FC2\n",
    "            z2 = myFCLayer(512, x2, 1)\n",
    "            z2 = np.append(z2, 1)           #add bias\n",
    "            z2list.append(z2)\n",
    "            x3 = myActivation(z2, \"ReLU\")\n",
    "            \n",
    "            #DO2\n",
    "            dm2 = myDropOut(x3, 0.2)\n",
    "            domask2.append(dm2)\n",
    "            x3 *= dm2\n",
    "            x3list.append(x3)\n",
    "            \n",
    "            #FC3\n",
    "            z3 = myFCLayer(10, x3, 2)\n",
    "            z3list.append(z3)\n",
    "            z3 = np.array(z3)\n",
    "            y = myActivation(z3, \"softmax\")\n",
    "            est.append(y)\n",
    "        \n",
    "        train_acc += myCalcAcc(est, Y_batch)            \n",
    "        train_E += myCrossEntropy(est, Y_batch)\n",
    "        \n",
    "        #back propagation\n",
    "        d3 = myCalcDeltaOut(est, Y_batch)\n",
    "        d2 = myCalcDelta(d3, 1, z2list)\n",
    "        d1 = myCalcDelta(d2, 2, z1list)\n",
    "        \n",
    "        DE3 = myCalcDE(d3, x3list)\n",
    "        DE2 = myCalcDE(d2, x2list)\n",
    "        DE1 = myCalcDE(d1, X_batch)\n",
    "        \n",
    "        myWeightUpdate_RMSProp(DE3, 3)\n",
    "        myWeightUpdate_RMSProp(DE2, 2)\n",
    "        myWeightUpdate_RMSProp(DE1, 1)\n",
    "        \n",
    "        cnt += len(X_batch)\n",
    "        sys.stdout.write(\"\\repoch[%d/%d] %d/%d\" % (ep + 1, epoch, cnt, len(X_train)))\n",
    "        \n",
    "    train_acc = train_acc / (X_train.shape[0] / batch_size)\n",
    "    train_E = train_E / X_train.shape[0]\n",
    "    \n",
    "    \n",
    "    #testing\n",
    "    test_est = []\n",
    "    test_z1list = []\n",
    "    test_x2list = []\n",
    "    test_z2list = []\n",
    "    test_x3list = []\n",
    "    test_z3list = []\n",
    "    \n",
    "    for test_x1 in X_test:\n",
    "        test_z1 = myFCLayer(512, test_x1, 0)\n",
    "        test_z1 = np.append(test_z1, 1)           #add bias\n",
    "        test_z1list.append(test_z1)\n",
    "        test_x2 = myActivation(test_z1, \"ReLU\")\n",
    "        test_x2list.append(test_x2)\n",
    "        \n",
    "        test_z2 = myFCLayer(512, test_x2, 1)\n",
    "        test_z2 = np.append(test_z2, 1)           #add bias\n",
    "        test_z2list.append(test_z2)\n",
    "        test_x3 = myActivation(test_z2, \"ReLU\")\n",
    "        test_x3list.append(test_x3)\n",
    "        \n",
    "        test_z3 = myFCLayer(10, test_x3, 2)\n",
    "        test_z3list.append(test_z3)\n",
    "        test_z3 = np.array(test_z3)\n",
    "        test_y = myActivation(test_z3, \"softmax\")\n",
    "        test_est.append(test_y)\n",
    "        \n",
    "    test_acc = myCalcAcc(test_est, Y_test)\n",
    "    test_acc_list.append(test_acc)\n",
    "    test_E = myCrossEntropy(test_est, Y_test) / X_test.shape[0]\n",
    "    test_loss_list.append(test_E)\n",
    "        \n",
    "    print(\"  train_acc = \" + \"{0:.8f}\".format(train_acc), end = \"\")\n",
    "    print(\"  train_loss = \" + \"{0:.8f}\".format(train_E), end = \"\")\n",
    "    print(\"  test_acc = \" + \"{0:.8f}\".format(test_acc), end = \"\")\n",
    "    print(\"  test_loss = \" + \"{0:.8f}\".format(test_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(-1, 21)\n",
    "plt.ylim(0.5, 1)\n",
    "tix = np.arange(0,21,2)\n",
    "tiy = np.arange(0.5,1.09,0.1)\n",
    "plt.xticks(tix)\n",
    "plt.yticks(tiy)\n",
    "plt.plot(range(epoch), test_acc_list)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
